{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import misc\n",
    "\n",
    "\n",
    "\n",
    "URLs = []\n",
    "\n",
    "with open('data/urls.txt', 'r') as f:\n",
    "    # read data as lines of text\n",
    "    URLs = [x.splitlines()[0] for x in list(f.readlines())]\n",
    "    \n",
    "def pixelGrabber(url):    \n",
    "    fl = cStringIO.StringIO(urllib2.urlopen(url).read())\n",
    "    im = misc.imread(fl)\n",
    "#     pixels = list(im)\n",
    "    images.append(im)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "from PIL import Image\n",
    "import scipy\n",
    "import scipy.misc\n",
    "import scipy.cluster\n",
    "import cStringIO\n",
    "import urllib2\n",
    "\n",
    "NUM_CLUSTERS = 5\n",
    "\n",
    "print 'reading image'\n",
    "   \n",
    "im = Image.open(\"images/Image1.jpg\")\n",
    "im = im.resize((150, 150))      # optional, to reduce time\n",
    "ar = scipy.misc.fromimage(im)\n",
    "shape = ar.shape\n",
    "ar = ar.reshape(scipy.product(shape[:2]), shape[2])\n",
    "\n",
    "print 'finding clusters'\n",
    "codes, dist = scipy.cluster.vq.kmeans(ar, NUM_CLUSTERS)\n",
    "print 'cluster centres:\\n', codes\n",
    "\n",
    "vecs, dist = scipy.cluster.vq.vq(ar, codes)         # assign codes\n",
    "counts, bins = scipy.histogram(vecs, len(codes))    # count occurrences\n",
    "\n",
    "index_max = scipy.argmax(counts)                    # find most frequent\n",
    "peak = codes[index_max]\n",
    "colour = ''.join(chr(c) for c in peak).encode('hex')\n",
    "print 'most frequent is %s (#%s)' % (peak, colour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading image\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'getpalette'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-9e582378a05e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'reading image'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'images/Image1.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpalette\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# shape = ar.shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'getpalette'"
     ]
    }
   ],
   "source": [
    "import struct\n",
    "from PIL import Image\n",
    "import scipy\n",
    "import scipy.misc\n",
    "import scipy.cluster\n",
    "\n",
    "NUM_CLUSTERS = 5\n",
    "\n",
    "print 'reading image'\n",
    "im = Image.open('images/Image1.jpg')\n",
    "colors = Image.getpalette(im)\n",
    "\n",
    "# shape = ar.shape\n",
    "# ar = ar.reshape(scipy.product(shape[:2]), shape[2])\n",
    "\n",
    "\n",
    "# print 'finding clusters'\n",
    "# codes, dist = scipy.cluster.vq.kmeans(ar, NUM_CLUSTERS)\n",
    "# print 'cluster centres:\\n', codes\n",
    "\n",
    "# vecs, dist = scipy.cluster.vq.vq(ar, codes)         # assign codes\n",
    "# counts, bins = scipy.histogram(vecs, len(codes))    # count occurrences\n",
    "\n",
    "# index_max = scipy.argmax(counts)                    # find most frequent\n",
    "# peak = codes[index_max]\n",
    "# colour = ''.join(chr(c) for c in peak).encode('hex')\n",
    "# print 'most frequent is %s (#%s)' % (peak, colour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, TimeoutError\n",
    "import time\n",
    "import os\n",
    "import csv\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pool = Pool(processes=4)              # start 4 worker processes\n",
    "    \n",
    "    URLs = []\n",
    "\n",
    "    with open('data/urls.txt', 'r') as f:\n",
    "        # read data as lines of text\n",
    "        URLs = [x.splitlines()[0] for x in list(f.readlines())]\n",
    "    \n",
    "    with open('data/output.csv', 'wb') as csvfile:\n",
    "        fieldnames = ['url', 'color1', 'color2', 'color3']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        writer.writerow(pool.map(pixelGrabber, URLs))\n",
    "\n",
    "    # print same numbers in arbitrary order\n",
    "    for i in pool.imap_unordered(f, range(10)):\n",
    "        print i\n",
    "\n",
    "    # evaluate \"f(20)\" asynchronously\n",
    "    res = pool.apply_async(f, (20,))      # runs in *only* one process\n",
    "    print res.get(timeout=1)              # prints \"400\"\n",
    "\n",
    "    # evaluate \"os.getpid()\" asynchronously\n",
    "    res = pool.apply_async(os.getpid, ()) # runs in *only* one process\n",
    "    print res.get(timeout=1)              # prints the PID of that process\n",
    "\n",
    "    # launching multiple evaluations asynchronously *may* use more processes\n",
    "    multiple_results = [pool.apply_async(os.getpid, ()) for i in range(4)]\n",
    "    print [res.get(timeout=1) for res in multiple_results]\n",
    "\n",
    "    # make a single worker sleep for 10 secs\n",
    "    res = pool.apply_async(time.sleep, (10,))\n",
    "    try:\n",
    "        print res.get(timeout=1)\n",
    "    except TimeoutError:\n",
    "        print \"We lacked patience and got a multiprocessing.TimeoutError\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    p = Pool(5)\n",
    "    print(p.map(pixelGrabber, URLs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
